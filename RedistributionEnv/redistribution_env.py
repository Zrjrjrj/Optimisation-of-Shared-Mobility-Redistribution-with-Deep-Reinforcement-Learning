import numpy as np
import gymnasium as gym
from gymnasium import spaces
import random
from typing import Tuple


class RedistributionEnv(gym.Env):
    metadata = {'render.modes': ['ansi']}

    def __init__(self, num_docks=5, dock_max_bikes=20, max_steps_per_episode=100, max_bikes_on_truck=5):
        self.num_docks = num_docks
        self.dock_max_bikes = dock_max_bikes
        self.max_steps_per_episode = max_steps_per_episode
        self.max_bikes_on_truck = max_bikes_on_truck
        self.action_space = spaces.Discrete(num_docks * (num_docks - 1) + 2)
        self.actions = {f"move_{i}_to_{j}": i * (num_docks - 1) + j - (1 if j > i else 0) for i in range(num_docks) for
                        j in range(num_docks) if i != j}
        self.actions["pickup"] = num_docks * (num_docks - 1)
        self.actions["dropoff"] = num_docks * (num_docks - 1) + 1
        self.observation_space = spaces.Dict({
            'truck_position': spaces.Discrete(num_docks),
            'bike_states': spaces.MultiDiscrete([dock_max_bikes + 1] * num_docks),
            'bikes_on_truck': spaces.Discrete(max_bikes_on_truck + 1)
        })
        self.distance_matrix = np.array([
            [0, 2, 5, 9, 4],
            [2, 0, 3, 7, 2],
            [5, 3, 0, 4, 3],
            [9, 7, 4, 0, 1],
            [4, 2, 3, 1, 0]
        ])
        self.lastaction = None
        self.reward_range = (-10, 60)
        self.state = None
        self.timestep = None

    def reset(self, seed=None, options=None):
        if seed is not None:
            np.random.seed(seed)
            random.seed(seed)

        self.state = {
            'truck_position': random.randint(0, self.num_docks - 1),
            'bike_states': np.random.randint(0, self.dock_max_bikes + 1, size=self.num_docks),
            'bikes_on_truck': 0
        }  # stateæ˜¯å­—å…¸æ ¼å¼ï¼Œä¸‰ä¸ªé”®å€¼
        total_bikes = np.sum(self.state['bike_states'])
        self.balanced_bikes = total_bikes // self.num_docks
        self.timestep = 0
        return self.state, {}

    def step(self, action) -> Tuple[dict, float, bool, bool, dict]:
        assert self.action_space.contains(action), "Invalid action"
        reward = -1  # æ¯ä¸ªæ—¶é—´æ­¥çš„å›ºå®šè´Ÿå¥–åŠ±
        terminated = False
        truncated = False
        info = {}

        if action < self.num_docks * (self.num_docks - 1):  # Movement
            from_station = action // (self.num_docks - 1)
            offset = action % (self.num_docks - 1)
            to_station = offset + (1 if offset >= from_station else 0)

            travel_cost = self.distance_matrix[from_station][to_station]

            # æ£€æŸ¥ä¸¤ä¸ªè½¦ç«™çš„è½¦è¾†æ•°é‡æ˜¯å¦éƒ½åœ¨å¹³å‡æ•°é‡çš„è¯¯å·®èŒƒå›´å†…
            if abs(self.state['bike_states'][from_station] - self.balanced_bikes) <= 1 and abs(
                    self.state['bike_states'][to_station] - self.balanced_bikes) <= 1:
                reward -= 2 + travel_cost  # æ— æ•ˆç§»åŠ¨æ—¶å¢åŠ æƒ©ç½š
            else:
                reward -= travel_cost  # å¢åŠ ç§»åŠ¨çš„æƒ©ç½š

            self.state['truck_position'] = to_station

        elif action == self.actions["pickup"]:  # Pickup bikes
            dock_index = self.state['truck_position']
            bikes_in_dock = self.state['bike_states'][dock_index]
            if bikes_in_dock > self.balanced_bikes and self.state['bikes_on_truck'] < self.max_bikes_on_truck:
                bikes_out = min(bikes_in_dock - int(np.ceil(self.balanced_bikes)),
                                self.max_bikes_on_truck - self.state['bikes_on_truck'])
                self.state['bike_states'][dock_index] -= bikes_out
                self.state['bikes_on_truck'] += bikes_out
                reward += 3  # fixed reward
                reward += 5 - bikes_out  # Encourage efficient redistribution
            else:
                reward -= 5

        elif action == self.actions["dropoff"]:  # Dropoff bikes
            dock_index = self.state['truck_position']
            bikes_in_dock = self.state['bike_states'][dock_index]
            if bikes_in_dock < self.balanced_bikes and self.state['bikes_on_truck'] > 0:
                bikes_needed = int(np.floor(self.balanced_bikes)) - bikes_in_dock
                bikes_out = min(bikes_needed, self.state['bikes_on_truck'])
                self.state['bike_states'][dock_index] += bikes_out
                self.state['bikes_on_truck'] -= bikes_out
                reward += 3  # fixed reward
                reward += 5 - bikes_out  # Encourage efficient redistribution
            else:
                reward -= 5

        # ç»è¿‡æµ‹è¯•è¿™ä¸€æ­¥å¯¹è·å¾—æœ€ç»ˆå¥–åŠ±å¾ˆé‡è¦ã€‚
        # Balance reward for individual stations. æ¯ä¸€æ­¥ä¸­æ£€æŸ¥æ‰€æœ‰ç«™ç‚¹çŠ¶æ€å¹¶ç»™äºˆæ¥è¿‘å¹³è¡¡çŠ¶æ€çš„å°é¢å¥–åŠ±ã€‚
        for bikes in self.state['bike_states']:
            if abs(bikes - self.balanced_bikes) <= 1:
                reward += 2  # Small reward for being close to balanced

        self.timestep += 1

        # Check for termination
        if np.all(np.abs(self.state['bike_states'] - self.balanced_bikes) <= 1) and self.state['bikes_on_truck'] == 0:
            terminated = True
            reward += 80  # Large reward for achieving overall balance
        elif self.timestep >= self.max_steps_per_episode:
            truncated = True
            info['reason'] = 'max_steps_reached'

        return self.state, reward, terminated, truncated, info

    def render(self, mode='ansi'):
        if mode != 'ansi':
            raise NotImplementedError("Render mode not supported: {}".format(mode))

        output = "\n"
        truck_position = self.state['truck_position']
        bike_states = self.state['bike_states']
        bikes_on_truck = self.state['bikes_on_truck']

        nodes = ['A', 'B', 'C', 'D', 'E']
        for idx in range(len(nodes)):
            if idx == truck_position:
                output += f"Station {nodes[idx]}: ğŸšš, {bike_states[idx]} bikes\n"
            else:
                output += f"Station {nodes[idx]}: âœ“, {bike_states[idx]} bikes\n"

        output += f"Bikes on Truck: {bikes_on_truck}\n"
        output += f"Current Timestep: {self.timestep}/{self.max_steps_per_episode}\n"

        print(output)

# # test
# # åˆ›å»ºç¯å¢ƒå®ä¾‹
# env = RedistributionEnv()
#
# # é‡ç½®ç¯å¢ƒï¼Œå¼€å§‹æ–°çš„episode
# state = env.reset(66)
#
# print("Initial State:")
# env.render()  # æ¸²æŸ“åˆå§‹çŠ¶æ€
# print('.......................................')
#
# # å°è¯•æ‰§è¡Œ Pickup åŠ¨ä½œ
# print("Attempting pickup...")
# pickup_action = env.actions['pickup']
# state, reward, terminated, _, _ = env.step(pickup_action)  # æ‰§è¡Œ pickup åŠ¨ä½œ
# print(f"Reward after pickup: {reward}, Done: {terminated}")
# env.render()  # æ¸²æŸ“åŠ¨ä½œåçš„çŠ¶æ€
#
# # æ‰§è¡Œ Movement åŠ¨ä½œ ä»0åˆ°3
# print("Attempting move_0_to_3...")
# move_0_to_3 = env.actions['move_0_to_3']
# state, reward, terminated, _, _ = env.step(move_0_to_3)
# print(f"Reward after move_0_to_3: {reward}, Done: {terminated}")
# env.render()
#
# # å°è¯•æ‰§è¡Œ Dropoff åŠ¨ä½œ
# print("Attempting dropoff...")
# dropoff_action = env.actions['dropoff']
# state, reward, terminated, _, _ = env.step(dropoff_action)  # æ‰§è¡Œ dropoff åŠ¨ä½œ
# print(f"Reward after dropoff: {reward}, Done: {terminated}")
# env.render()  # æ¸²æŸ“åŠ¨ä½œåçš„çŠ¶æ€
#
# print("....................................................")
# print("....................................................")
# print("Attempting movement...")
#
# # éå†æ‰€æœ‰è½¦ç«™çš„æ‰€æœ‰å¯èƒ½ç§»åŠ¨
# for from_station in range(env.num_docks):
#     for to_station in range(env.num_docks):
#         if from_station != to_station:
#             # é‡ç½®åˆ°èµ·å§‹ç«™ç‚¹
#             env.state['truck_position'] = from_station
#             env.render()
#             print(f"Move from Station {from_station} to Station {to_station}")
#             # æ‰§è¡Œç§»åŠ¨åŠ¨ä½œ
#             action = env.actions[f"move_{from_station}_to_{to_station}"]
#             _, reward, terminated, _, _ = env.step(action)
#             print(f"Performed move from {from_station} to {to_station}")
#             print(f"Reward: {reward}, Done: {terminated}")
#             env.render()  # æ¸²æŸ“æ¯ä¸ªåŠ¨ä½œä¹‹åçš„çŠ¶æ€
#             print('*********************************')
